{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.MNIST数据集的定义及载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as nf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_dir = '../processed_data/train/'\n",
    "val_dir = '../processed_data/val/'\n",
    "test_dir = '../processed_data/test/'\n",
    "# 对数据进行归一化\n",
    "transform = transforms.Compose([transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, root_dir,setname,transform = None):\n",
    "        self.setname = setname\n",
    "        self.root_dir = root_dir\n",
    "        self.subfolders = sorted(os.listdir(root_dir))\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        if (self.setname=='train') or (self.setname=='val'):\n",
    "            for label, subfolder in enumerate(self.subfolders):\n",
    "                folder_path = os.path.join(root_dir, subfolder)\n",
    "                file_list = sorted(os.listdir(folder_path))\n",
    "\n",
    "                for file_name in file_list:\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    data = torch.from_numpy(np.load(file_path))\n",
    "                    self.data.append(data)\n",
    "                    self.labels.append(label)\n",
    "        else: #测试集数据\n",
    "            file_list = sorted(os.listdir(root_dir))\n",
    "            for file_name in file_list:\n",
    "                file_path = os.path.join(root_dir, file_name)\n",
    "                data = torch.from_numpy(np.load(file_path))\n",
    "                self.data.append(data)\n",
    "                # self.labels.append(label) 测试数据无标签\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if (self.setname=='train') or (self.setname=='val'):\n",
    "            data_pair = {\n",
    "                'data': self.data[idx],\n",
    "                'label': self.labels[idx]\n",
    "            }\n",
    "            if self.transform:\n",
    "                data_pair['data'] = self.transform(data_pair['data'])\n",
    "        else:\n",
    "            data_pair = {\n",
    "                'data': self.data[idx]\n",
    "            }\n",
    "            if self.transform:\n",
    "                data_pair['data'] = self.transform(data_pair['data'])\n",
    "        return data_pair\n",
    "\n",
    "train_dataset = MNIST_Dataset(train_dir,\"train\", transform = transform)\n",
    "val_dataset = MNIST_Dataset(val_dir,\"val\", transform = transform)\n",
    "test_dataset = MNIST_Dataset(test_dir,\"test\", transform = transform)\n",
    "#分别创建两个DataLoader载入训练集与测试集的数据\n",
    "# 注意batch-size表示每批样本的大小，一次训练迭代一个batch.因此len(data_train_loader)表示mini-batch的数目\n",
    "#batch_idx表示batch批的数目下标\n",
    "data_train_loader = DataLoader(train_dataset, batch_size=1024 ,shuffle = True, num_workers=0,drop_last = False)  # 训练集的数据被随机打乱\n",
    "data_val_loader = DataLoader(val_dataset, batch_size=10 ,shuffle = False, num_workers=0,drop_last = False)  # 训练集的数据被随机打乱\n",
    "data_test_loader = DataLoader(test_dataset, batch_size=256 ,shuffle = False, num_workers=0,drop_last = False)  # 训练集的数据被随机打乱\n",
    "num_data_val = len(val_dataset)\n",
    "num_batch_val = np.ceil(num_data_val / data_val_loader.batch_size)\n",
    "# print(num_batch_val)\n",
    "# print(len(train_dataset))\n",
    "# print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2.构建CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(10, 50, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(50, 100, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1600, 200),\n",
    "            torch.nn.Linear(200, 20),\n",
    "            torch.nn.Linear(20, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv1(x)  \n",
    "        x = self.conv2(x) \n",
    "        # print(x.shape)\n",
    "        x = x.view(batch_size, -1)  # flatten 变成全连接网络需要的输入 (batch, 20,4,4) ==> (batch,320), -1 此处自动算出的是320\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x  # 最后输出的是维度为10的，也就是（对应数学符号的0~9）\n",
    "\n",
    "model = Net().to(device) # 实例化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4. 确定训练时需要的优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()  # 切换模型到训练状态\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay = 5e-4)  # lr学习率，momentum冲量\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.99, last_epoch=-1)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part5.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch_idx: 5]: loss: 0.023 , acc: 14.18 %\n",
      "[epoch: 1, batch_idx: 10]: loss: 0.023 , acc: 25.04 %\n",
      "[epoch: 1, batch_idx: 15]: loss: 0.022 , acc: 52.60 %\n",
      "[epoch: 1, batch_idx: 20]: loss: 0.022 , acc: 58.48 %\n",
      "[epoch: 1, batch_idx: 25]: loss: 0.020 , acc: 65.33 %\n",
      "[epoch: 1, batch_idx: 30]: loss: 0.018 , acc: 73.01 %\n",
      "[epoch: 1, batch_idx: 35]: loss: 0.013 , acc: 73.16 %\n",
      "[epoch: 1, batch_idx: 40]: loss: 0.010 , acc: 72.97 %\n",
      "[epoch: 1, batch_idx: 45]: loss: 0.008 , acc: 88.65 %\n",
      "[epoch: 1, batch_idx: 50]: loss: 0.008 , acc: 89.18 %\n",
      "[epoch: 1, batch_idx: 55]: loss: 0.009 , acc: 89.77 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 2, batch_idx: 5]: loss: 0.006 , acc: 88.43 %\n",
      "[epoch: 2, batch_idx: 10]: loss: 0.006 , acc: 90.20 %\n",
      "[epoch: 2, batch_idx: 15]: loss: 0.006 , acc: 89.86 %\n",
      "[epoch: 2, batch_idx: 20]: loss: 0.006 , acc: 89.90 %\n",
      "[epoch: 2, batch_idx: 25]: loss: 0.006 , acc: 89.55 %\n",
      "[epoch: 2, batch_idx: 30]: loss: 0.005 , acc: 90.35 %\n",
      "[epoch: 2, batch_idx: 35]: loss: 0.006 , acc: 90.02 %\n",
      "[epoch: 2, batch_idx: 40]: loss: 0.005 , acc: 90.12 %\n",
      "[epoch: 2, batch_idx: 45]: loss: 0.006 , acc: 90.00 %\n",
      "[epoch: 2, batch_idx: 50]: loss: 0.005 , acc: 89.94 %\n",
      "[epoch: 2, batch_idx: 55]: loss: 0.006 , acc: 89.61 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 3, batch_idx: 5]: loss: 0.005 , acc: 88.68 %\n",
      "[epoch: 3, batch_idx: 10]: loss: 0.005 , acc: 89.94 %\n",
      "[epoch: 3, batch_idx: 15]: loss: 0.006 , acc: 89.69 %\n",
      "[epoch: 3, batch_idx: 20]: loss: 0.005 , acc: 90.88 %\n",
      "[epoch: 3, batch_idx: 25]: loss: 0.005 , acc: 90.16 %\n",
      "[epoch: 3, batch_idx: 30]: loss: 0.005 , acc: 89.65 %\n",
      "[epoch: 3, batch_idx: 35]: loss: 0.005 , acc: 89.88 %\n",
      "[epoch: 3, batch_idx: 40]: loss: 0.006 , acc: 89.94 %\n",
      "[epoch: 3, batch_idx: 45]: loss: 0.005 , acc: 90.72 %\n",
      "[epoch: 3, batch_idx: 50]: loss: 0.005 , acc: 89.47 %\n",
      "[epoch: 3, batch_idx: 55]: loss: 0.005 , acc: 88.77 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 4, batch_idx: 5]: loss: 0.004 , acc: 88.45 %\n",
      "[epoch: 4, batch_idx: 10]: loss: 0.005 , acc: 90.18 %\n",
      "[epoch: 4, batch_idx: 15]: loss: 0.005 , acc: 89.94 %\n",
      "[epoch: 4, batch_idx: 20]: loss: 0.005 , acc: 90.23 %\n",
      "[epoch: 4, batch_idx: 25]: loss: 0.005 , acc: 89.53 %\n",
      "[epoch: 4, batch_idx: 30]: loss: 0.005 , acc: 89.86 %\n",
      "[epoch: 4, batch_idx: 35]: loss: 0.005 , acc: 89.22 %\n",
      "[epoch: 4, batch_idx: 40]: loss: 0.005 , acc: 89.92 %\n",
      "[epoch: 4, batch_idx: 45]: loss: 0.004 , acc: 89.49 %\n",
      "[epoch: 4, batch_idx: 50]: loss: 0.005 , acc: 89.65 %\n",
      "[epoch: 4, batch_idx: 55]: loss: 0.005 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 12.0 % \n",
      "[epoch: 5, batch_idx: 5]: loss: 0.005 , acc: 88.24 %\n",
      "[epoch: 5, batch_idx: 10]: loss: 0.005 , acc: 89.71 %\n",
      "[epoch: 5, batch_idx: 15]: loss: 0.004 , acc: 90.37 %\n",
      "[epoch: 5, batch_idx: 20]: loss: 0.005 , acc: 89.24 %\n",
      "[epoch: 5, batch_idx: 25]: loss: 0.004 , acc: 89.18 %\n",
      "[epoch: 5, batch_idx: 30]: loss: 0.005 , acc: 89.22 %\n",
      "[epoch: 5, batch_idx: 35]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 5, batch_idx: 40]: loss: 0.005 , acc: 89.53 %\n",
      "[epoch: 5, batch_idx: 45]: loss: 0.004 , acc: 90.06 %\n",
      "[epoch: 5, batch_idx: 50]: loss: 0.005 , acc: 89.86 %\n",
      "[epoch: 5, batch_idx: 55]: loss: 0.005 , acc: 89.20 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 6, batch_idx: 5]: loss: 0.005 , acc: 88.10 %\n",
      "[epoch: 6, batch_idx: 10]: loss: 0.005 , acc: 89.12 %\n",
      "[epoch: 6, batch_idx: 15]: loss: 0.004 , acc: 89.49 %\n",
      "[epoch: 6, batch_idx: 20]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 6, batch_idx: 25]: loss: 0.004 , acc: 90.04 %\n",
      "[epoch: 6, batch_idx: 30]: loss: 0.005 , acc: 89.82 %\n",
      "[epoch: 6, batch_idx: 35]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 6, batch_idx: 40]: loss: 0.004 , acc: 89.59 %\n",
      "[epoch: 6, batch_idx: 45]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 6, batch_idx: 50]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 6, batch_idx: 55]: loss: 0.005 , acc: 89.08 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 7, batch_idx: 5]: loss: 0.004 , acc: 88.49 %\n",
      "[epoch: 7, batch_idx: 10]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 7, batch_idx: 15]: loss: 0.005 , acc: 90.04 %\n",
      "[epoch: 7, batch_idx: 20]: loss: 0.005 , acc: 90.43 %\n",
      "[epoch: 7, batch_idx: 25]: loss: 0.004 , acc: 90.18 %\n",
      "[epoch: 7, batch_idx: 30]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 7, batch_idx: 35]: loss: 0.005 , acc: 89.00 %\n",
      "[epoch: 7, batch_idx: 40]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 7, batch_idx: 45]: loss: 0.005 , acc: 89.16 %\n",
      "[epoch: 7, batch_idx: 50]: loss: 0.005 , acc: 89.36 %\n",
      "[epoch: 7, batch_idx: 55]: loss: 0.004 , acc: 89.51 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 16.0 % \n",
      "[epoch: 8, batch_idx: 5]: loss: 0.004 , acc: 87.72 %\n",
      "[epoch: 8, batch_idx: 10]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 8, batch_idx: 15]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 8, batch_idx: 20]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 8, batch_idx: 25]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 8, batch_idx: 30]: loss: 0.004 , acc: 89.51 %\n",
      "[epoch: 8, batch_idx: 35]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 8, batch_idx: 40]: loss: 0.005 , acc: 89.55 %\n",
      "[epoch: 8, batch_idx: 45]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 8, batch_idx: 50]: loss: 0.004 , acc: 89.26 %\n",
      "[epoch: 8, batch_idx: 55]: loss: 0.004 , acc: 89.00 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 16.0 % \n",
      "[epoch: 9, batch_idx: 5]: loss: 0.004 , acc: 88.45 %\n",
      "[epoch: 9, batch_idx: 10]: loss: 0.005 , acc: 88.81 %\n",
      "[epoch: 9, batch_idx: 15]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 9, batch_idx: 20]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 9, batch_idx: 25]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 9, batch_idx: 30]: loss: 0.004 , acc: 90.53 %\n",
      "[epoch: 9, batch_idx: 35]: loss: 0.005 , acc: 89.55 %\n",
      "[epoch: 9, batch_idx: 40]: loss: 0.004 , acc: 89.22 %\n",
      "[epoch: 9, batch_idx: 45]: loss: 0.004 , acc: 89.26 %\n",
      "[epoch: 9, batch_idx: 50]: loss: 0.004 , acc: 90.33 %\n",
      "[epoch: 9, batch_idx: 55]: loss: 0.004 , acc: 89.65 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 10, batch_idx: 5]: loss: 0.004 , acc: 87.93 %\n",
      "[epoch: 10, batch_idx: 10]: loss: 0.004 , acc: 90.10 %\n",
      "[epoch: 10, batch_idx: 15]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 10, batch_idx: 20]: loss: 0.004 , acc: 89.22 %\n",
      "[epoch: 10, batch_idx: 25]: loss: 0.004 , acc: 89.86 %\n",
      "[epoch: 10, batch_idx: 30]: loss: 0.005 , acc: 88.83 %\n",
      "[epoch: 10, batch_idx: 35]: loss: 0.005 , acc: 89.57 %\n",
      "[epoch: 10, batch_idx: 40]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 10, batch_idx: 45]: loss: 0.004 , acc: 89.75 %\n",
      "[epoch: 10, batch_idx: 50]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 10, batch_idx: 55]: loss: 0.004 , acc: 89.61 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 11, batch_idx: 5]: loss: 0.004 , acc: 88.51 %\n",
      "[epoch: 11, batch_idx: 10]: loss: 0.004 , acc: 90.10 %\n",
      "[epoch: 11, batch_idx: 15]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 11, batch_idx: 20]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 11, batch_idx: 25]: loss: 0.004 , acc: 89.28 %\n",
      "[epoch: 11, batch_idx: 30]: loss: 0.004 , acc: 88.28 %\n",
      "[epoch: 11, batch_idx: 35]: loss: 0.004 , acc: 88.63 %\n",
      "[epoch: 11, batch_idx: 40]: loss: 0.004 , acc: 89.51 %\n",
      "[epoch: 11, batch_idx: 45]: loss: 0.004 , acc: 90.14 %\n",
      "[epoch: 11, batch_idx: 50]: loss: 0.004 , acc: 89.82 %\n",
      "[epoch: 11, batch_idx: 55]: loss: 0.005 , acc: 89.86 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 12, batch_idx: 5]: loss: 0.004 , acc: 88.33 %\n",
      "[epoch: 12, batch_idx: 10]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 12, batch_idx: 15]: loss: 0.004 , acc: 89.18 %\n",
      "[epoch: 12, batch_idx: 20]: loss: 0.004 , acc: 88.67 %\n",
      "[epoch: 12, batch_idx: 25]: loss: 0.004 , acc: 90.16 %\n",
      "[epoch: 12, batch_idx: 30]: loss: 0.004 , acc: 90.53 %\n",
      "[epoch: 12, batch_idx: 35]: loss: 0.004 , acc: 89.00 %\n",
      "[epoch: 12, batch_idx: 40]: loss: 0.004 , acc: 90.23 %\n",
      "[epoch: 12, batch_idx: 45]: loss: 0.004 , acc: 88.95 %\n",
      "[epoch: 12, batch_idx: 50]: loss: 0.004 , acc: 89.98 %\n",
      "[epoch: 12, batch_idx: 55]: loss: 0.004 , acc: 90.47 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 13, batch_idx: 5]: loss: 0.004 , acc: 88.39 %\n",
      "[epoch: 13, batch_idx: 10]: loss: 0.004 , acc: 89.14 %\n",
      "[epoch: 13, batch_idx: 15]: loss: 0.004 , acc: 89.20 %\n",
      "[epoch: 13, batch_idx: 20]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 13, batch_idx: 25]: loss: 0.005 , acc: 89.71 %\n",
      "[epoch: 13, batch_idx: 30]: loss: 0.004 , acc: 89.18 %\n",
      "[epoch: 13, batch_idx: 35]: loss: 0.004 , acc: 89.98 %\n",
      "[epoch: 13, batch_idx: 40]: loss: 0.004 , acc: 89.98 %\n",
      "[epoch: 13, batch_idx: 45]: loss: 0.004 , acc: 89.30 %\n",
      "[epoch: 13, batch_idx: 50]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 13, batch_idx: 55]: loss: 0.004 , acc: 89.16 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 14, batch_idx: 5]: loss: 0.004 , acc: 88.03 %\n",
      "[epoch: 14, batch_idx: 10]: loss: 0.004 , acc: 89.53 %\n",
      "[epoch: 14, batch_idx: 15]: loss: 0.004 , acc: 89.00 %\n",
      "[epoch: 14, batch_idx: 20]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 14, batch_idx: 25]: loss: 0.004 , acc: 89.14 %\n",
      "[epoch: 14, batch_idx: 30]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 14, batch_idx: 35]: loss: 0.004 , acc: 89.32 %\n",
      "[epoch: 14, batch_idx: 40]: loss: 0.005 , acc: 89.86 %\n",
      "[epoch: 14, batch_idx: 45]: loss: 0.004 , acc: 90.14 %\n",
      "[epoch: 14, batch_idx: 50]: loss: 0.003 , acc: 90.21 %\n",
      "[epoch: 14, batch_idx: 55]: loss: 0.004 , acc: 90.27 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 15, batch_idx: 5]: loss: 0.004 , acc: 88.12 %\n",
      "[epoch: 15, batch_idx: 10]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 15, batch_idx: 15]: loss: 0.004 , acc: 89.22 %\n",
      "[epoch: 15, batch_idx: 20]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 15, batch_idx: 25]: loss: 0.004 , acc: 90.16 %\n",
      "[epoch: 15, batch_idx: 30]: loss: 0.004 , acc: 88.73 %\n",
      "[epoch: 15, batch_idx: 35]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 15, batch_idx: 40]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 15, batch_idx: 45]: loss: 0.004 , acc: 90.35 %\n",
      "[epoch: 15, batch_idx: 50]: loss: 0.004 , acc: 89.49 %\n",
      "[epoch: 15, batch_idx: 55]: loss: 0.004 , acc: 89.39 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 16, batch_idx: 5]: loss: 0.004 , acc: 88.64 %\n",
      "[epoch: 16, batch_idx: 10]: loss: 0.004 , acc: 90.66 %\n",
      "[epoch: 16, batch_idx: 15]: loss: 0.004 , acc: 89.08 %\n",
      "[epoch: 16, batch_idx: 20]: loss: 0.004 , acc: 88.69 %\n",
      "[epoch: 16, batch_idx: 25]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 16, batch_idx: 30]: loss: 0.004 , acc: 89.49 %\n",
      "[epoch: 16, batch_idx: 35]: loss: 0.004 , acc: 90.92 %\n",
      "[epoch: 16, batch_idx: 40]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 16, batch_idx: 45]: loss: 0.004 , acc: 89.32 %\n",
      "[epoch: 16, batch_idx: 50]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 16, batch_idx: 55]: loss: 0.004 , acc: 88.85 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 17, batch_idx: 5]: loss: 0.004 , acc: 87.59 %\n",
      "[epoch: 17, batch_idx: 10]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 17, batch_idx: 15]: loss: 0.003 , acc: 89.57 %\n",
      "[epoch: 17, batch_idx: 20]: loss: 0.004 , acc: 90.18 %\n",
      "[epoch: 17, batch_idx: 25]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 17, batch_idx: 30]: loss: 0.004 , acc: 89.75 %\n",
      "[epoch: 17, batch_idx: 35]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 17, batch_idx: 40]: loss: 0.004 , acc: 89.32 %\n",
      "[epoch: 17, batch_idx: 45]: loss: 0.004 , acc: 88.79 %\n",
      "[epoch: 17, batch_idx: 50]: loss: 0.004 , acc: 89.98 %\n",
      "[epoch: 17, batch_idx: 55]: loss: 0.004 , acc: 90.04 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 18, batch_idx: 5]: loss: 0.004 , acc: 88.47 %\n",
      "[epoch: 18, batch_idx: 10]: loss: 0.004 , acc: 89.69 %\n",
      "[epoch: 18, batch_idx: 15]: loss: 0.004 , acc: 89.55 %\n",
      "[epoch: 18, batch_idx: 20]: loss: 0.004 , acc: 89.86 %\n",
      "[epoch: 18, batch_idx: 25]: loss: 0.004 , acc: 90.18 %\n",
      "[epoch: 18, batch_idx: 30]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 18, batch_idx: 35]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 18, batch_idx: 40]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 18, batch_idx: 45]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 18, batch_idx: 50]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 18, batch_idx: 55]: loss: 0.004 , acc: 89.51 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 19, batch_idx: 5]: loss: 0.004 , acc: 87.91 %\n",
      "[epoch: 19, batch_idx: 10]: loss: 0.003 , acc: 90.39 %\n",
      "[epoch: 19, batch_idx: 15]: loss: 0.003 , acc: 89.77 %\n",
      "[epoch: 19, batch_idx: 20]: loss: 0.004 , acc: 88.93 %\n",
      "[epoch: 19, batch_idx: 25]: loss: 0.004 , acc: 90.45 %\n",
      "[epoch: 19, batch_idx: 30]: loss: 0.004 , acc: 89.96 %\n",
      "[epoch: 19, batch_idx: 35]: loss: 0.004 , acc: 89.94 %\n",
      "[epoch: 19, batch_idx: 40]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 19, batch_idx: 45]: loss: 0.003 , acc: 89.73 %\n",
      "[epoch: 19, batch_idx: 50]: loss: 0.004 , acc: 88.93 %\n",
      "[epoch: 19, batch_idx: 55]: loss: 0.004 , acc: 89.57 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 20, batch_idx: 5]: loss: 0.003 , acc: 89.64 %\n",
      "[epoch: 20, batch_idx: 10]: loss: 0.004 , acc: 89.20 %\n",
      "[epoch: 20, batch_idx: 15]: loss: 0.003 , acc: 90.21 %\n",
      "[epoch: 20, batch_idx: 20]: loss: 0.004 , acc: 89.30 %\n",
      "[epoch: 20, batch_idx: 25]: loss: 0.004 , acc: 88.96 %\n",
      "[epoch: 20, batch_idx: 30]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 20, batch_idx: 35]: loss: 0.004 , acc: 90.04 %\n",
      "[epoch: 20, batch_idx: 40]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 20, batch_idx: 45]: loss: 0.004 , acc: 90.27 %\n",
      "[epoch: 20, batch_idx: 50]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 20, batch_idx: 55]: loss: 0.004 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 21, batch_idx: 5]: loss: 0.004 , acc: 87.74 %\n",
      "[epoch: 21, batch_idx: 10]: loss: 0.004 , acc: 89.30 %\n",
      "[epoch: 21, batch_idx: 15]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 21, batch_idx: 20]: loss: 0.004 , acc: 89.55 %\n",
      "[epoch: 21, batch_idx: 25]: loss: 0.004 , acc: 89.00 %\n",
      "[epoch: 21, batch_idx: 30]: loss: 0.003 , acc: 89.88 %\n",
      "[epoch: 21, batch_idx: 35]: loss: 0.004 , acc: 90.10 %\n",
      "[epoch: 21, batch_idx: 40]: loss: 0.004 , acc: 90.00 %\n",
      "[epoch: 21, batch_idx: 45]: loss: 0.003 , acc: 90.74 %\n",
      "[epoch: 21, batch_idx: 50]: loss: 0.004 , acc: 90.04 %\n",
      "[epoch: 21, batch_idx: 55]: loss: 0.004 , acc: 89.71 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 22, batch_idx: 5]: loss: 0.004 , acc: 88.79 %\n",
      "[epoch: 22, batch_idx: 10]: loss: 0.004 , acc: 89.79 %\n",
      "[epoch: 22, batch_idx: 15]: loss: 0.004 , acc: 89.47 %\n",
      "[epoch: 22, batch_idx: 20]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 22, batch_idx: 25]: loss: 0.004 , acc: 89.80 %\n",
      "[epoch: 22, batch_idx: 30]: loss: 0.004 , acc: 90.31 %\n",
      "[epoch: 22, batch_idx: 35]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 22, batch_idx: 40]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 22, batch_idx: 45]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 22, batch_idx: 50]: loss: 0.004 , acc: 89.02 %\n",
      "[epoch: 22, batch_idx: 55]: loss: 0.004 , acc: 89.79 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 23, batch_idx: 5]: loss: 0.003 , acc: 88.16 %\n",
      "[epoch: 23, batch_idx: 10]: loss: 0.004 , acc: 89.32 %\n",
      "[epoch: 23, batch_idx: 15]: loss: 0.004 , acc: 90.49 %\n",
      "[epoch: 23, batch_idx: 20]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 23, batch_idx: 25]: loss: 0.004 , acc: 89.02 %\n",
      "[epoch: 23, batch_idx: 30]: loss: 0.004 , acc: 89.51 %\n",
      "[epoch: 23, batch_idx: 35]: loss: 0.003 , acc: 90.10 %\n",
      "[epoch: 23, batch_idx: 40]: loss: 0.004 , acc: 89.82 %\n",
      "[epoch: 23, batch_idx: 45]: loss: 0.004 , acc: 89.39 %\n",
      "[epoch: 23, batch_idx: 50]: loss: 0.004 , acc: 90.20 %\n",
      "[epoch: 23, batch_idx: 55]: loss: 0.004 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 24, batch_idx: 5]: loss: 0.004 , acc: 88.20 %\n",
      "[epoch: 24, batch_idx: 10]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 24, batch_idx: 15]: loss: 0.004 , acc: 89.94 %\n",
      "[epoch: 24, batch_idx: 20]: loss: 0.004 , acc: 90.29 %\n",
      "[epoch: 24, batch_idx: 25]: loss: 0.004 , acc: 89.55 %\n",
      "[epoch: 24, batch_idx: 30]: loss: 0.003 , acc: 90.55 %\n",
      "[epoch: 24, batch_idx: 35]: loss: 0.004 , acc: 90.33 %\n",
      "[epoch: 24, batch_idx: 40]: loss: 0.004 , acc: 89.22 %\n",
      "[epoch: 24, batch_idx: 45]: loss: 0.004 , acc: 89.24 %\n",
      "[epoch: 24, batch_idx: 50]: loss: 0.003 , acc: 90.16 %\n",
      "[epoch: 24, batch_idx: 55]: loss: 0.004 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 25, batch_idx: 5]: loss: 0.004 , acc: 87.72 %\n",
      "[epoch: 25, batch_idx: 10]: loss: 0.004 , acc: 88.24 %\n",
      "[epoch: 25, batch_idx: 15]: loss: 0.004 , acc: 89.51 %\n",
      "[epoch: 25, batch_idx: 20]: loss: 0.003 , acc: 90.45 %\n",
      "[epoch: 25, batch_idx: 25]: loss: 0.004 , acc: 90.51 %\n",
      "[epoch: 25, batch_idx: 30]: loss: 0.003 , acc: 90.06 %\n",
      "[epoch: 25, batch_idx: 35]: loss: 0.004 , acc: 89.79 %\n",
      "[epoch: 25, batch_idx: 40]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 25, batch_idx: 45]: loss: 0.004 , acc: 90.39 %\n",
      "[epoch: 25, batch_idx: 50]: loss: 0.003 , acc: 90.25 %\n",
      "[epoch: 25, batch_idx: 55]: loss: 0.004 , acc: 88.83 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 16.0 % \n",
      "[epoch: 26, batch_idx: 5]: loss: 0.004 , acc: 88.08 %\n",
      "[epoch: 26, batch_idx: 10]: loss: 0.004 , acc: 90.29 %\n",
      "[epoch: 26, batch_idx: 15]: loss: 0.004 , acc: 89.45 %\n",
      "[epoch: 26, batch_idx: 20]: loss: 0.003 , acc: 89.14 %\n",
      "[epoch: 26, batch_idx: 25]: loss: 0.003 , acc: 89.86 %\n",
      "[epoch: 26, batch_idx: 30]: loss: 0.004 , acc: 89.84 %\n",
      "[epoch: 26, batch_idx: 35]: loss: 0.003 , acc: 89.57 %\n",
      "[epoch: 26, batch_idx: 40]: loss: 0.003 , acc: 90.02 %\n",
      "[epoch: 26, batch_idx: 45]: loss: 0.004 , acc: 89.69 %\n",
      "[epoch: 26, batch_idx: 50]: loss: 0.004 , acc: 90.43 %\n",
      "[epoch: 26, batch_idx: 55]: loss: 0.003 , acc: 89.65 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 27, batch_idx: 5]: loss: 0.003 , acc: 88.74 %\n",
      "[epoch: 27, batch_idx: 10]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 27, batch_idx: 15]: loss: 0.004 , acc: 88.52 %\n",
      "[epoch: 27, batch_idx: 20]: loss: 0.003 , acc: 89.77 %\n",
      "[epoch: 27, batch_idx: 25]: loss: 0.004 , acc: 89.59 %\n",
      "[epoch: 27, batch_idx: 30]: loss: 0.004 , acc: 89.10 %\n",
      "[epoch: 27, batch_idx: 35]: loss: 0.004 , acc: 90.16 %\n",
      "[epoch: 27, batch_idx: 40]: loss: 0.003 , acc: 90.35 %\n",
      "[epoch: 27, batch_idx: 45]: loss: 0.004 , acc: 88.96 %\n",
      "[epoch: 27, batch_idx: 50]: loss: 0.004 , acc: 90.29 %\n",
      "[epoch: 27, batch_idx: 55]: loss: 0.003 , acc: 91.27 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 28, batch_idx: 5]: loss: 0.003 , acc: 88.68 %\n",
      "[epoch: 28, batch_idx: 10]: loss: 0.004 , acc: 89.43 %\n",
      "[epoch: 28, batch_idx: 15]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 28, batch_idx: 20]: loss: 0.004 , acc: 89.08 %\n",
      "[epoch: 28, batch_idx: 25]: loss: 0.004 , acc: 89.55 %\n",
      "[epoch: 28, batch_idx: 30]: loss: 0.003 , acc: 90.59 %\n",
      "[epoch: 28, batch_idx: 35]: loss: 0.003 , acc: 89.53 %\n",
      "[epoch: 28, batch_idx: 40]: loss: 0.003 , acc: 89.36 %\n",
      "[epoch: 28, batch_idx: 45]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 28, batch_idx: 50]: loss: 0.003 , acc: 90.80 %\n",
      "[epoch: 28, batch_idx: 55]: loss: 0.004 , acc: 90.20 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 29, batch_idx: 5]: loss: 0.004 , acc: 88.70 %\n",
      "[epoch: 29, batch_idx: 10]: loss: 0.004 , acc: 89.94 %\n",
      "[epoch: 29, batch_idx: 15]: loss: 0.004 , acc: 89.96 %\n",
      "[epoch: 29, batch_idx: 20]: loss: 0.003 , acc: 90.00 %\n",
      "[epoch: 29, batch_idx: 25]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 29, batch_idx: 30]: loss: 0.004 , acc: 90.00 %\n",
      "[epoch: 29, batch_idx: 35]: loss: 0.004 , acc: 89.90 %\n",
      "[epoch: 29, batch_idx: 40]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 29, batch_idx: 45]: loss: 0.004 , acc: 89.08 %\n",
      "[epoch: 29, batch_idx: 50]: loss: 0.003 , acc: 90.04 %\n",
      "[epoch: 29, batch_idx: 55]: loss: 0.004 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 30, batch_idx: 5]: loss: 0.003 , acc: 88.16 %\n",
      "[epoch: 30, batch_idx: 10]: loss: 0.004 , acc: 90.12 %\n",
      "[epoch: 30, batch_idx: 15]: loss: 0.004 , acc: 90.43 %\n",
      "[epoch: 30, batch_idx: 20]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 30, batch_idx: 25]: loss: 0.004 , acc: 89.59 %\n",
      "[epoch: 30, batch_idx: 30]: loss: 0.004 , acc: 89.45 %\n",
      "[epoch: 30, batch_idx: 35]: loss: 0.004 , acc: 89.82 %\n",
      "[epoch: 30, batch_idx: 40]: loss: 0.004 , acc: 89.71 %\n",
      "[epoch: 30, batch_idx: 45]: loss: 0.003 , acc: 89.71 %\n",
      "[epoch: 30, batch_idx: 50]: loss: 0.003 , acc: 90.06 %\n",
      "[epoch: 30, batch_idx: 55]: loss: 0.004 , acc: 88.85 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 19.0 % \n",
      "[epoch: 31, batch_idx: 5]: loss: 0.004 , acc: 88.37 %\n",
      "[epoch: 31, batch_idx: 10]: loss: 0.004 , acc: 90.04 %\n",
      "[epoch: 31, batch_idx: 15]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 31, batch_idx: 20]: loss: 0.004 , acc: 89.47 %\n",
      "[epoch: 31, batch_idx: 25]: loss: 0.003 , acc: 89.55 %\n",
      "[epoch: 31, batch_idx: 30]: loss: 0.003 , acc: 89.94 %\n",
      "[epoch: 31, batch_idx: 35]: loss: 0.004 , acc: 88.38 %\n",
      "[epoch: 31, batch_idx: 40]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 31, batch_idx: 45]: loss: 0.003 , acc: 90.31 %\n",
      "[epoch: 31, batch_idx: 50]: loss: 0.003 , acc: 90.00 %\n",
      "[epoch: 31, batch_idx: 55]: loss: 0.003 , acc: 89.57 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 32, batch_idx: 5]: loss: 0.004 , acc: 87.51 %\n",
      "[epoch: 32, batch_idx: 10]: loss: 0.004 , acc: 89.82 %\n",
      "[epoch: 32, batch_idx: 15]: loss: 0.004 , acc: 89.79 %\n",
      "[epoch: 32, batch_idx: 20]: loss: 0.004 , acc: 88.91 %\n",
      "[epoch: 32, batch_idx: 25]: loss: 0.004 , acc: 89.80 %\n",
      "[epoch: 32, batch_idx: 30]: loss: 0.004 , acc: 89.24 %\n",
      "[epoch: 32, batch_idx: 35]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 32, batch_idx: 40]: loss: 0.003 , acc: 90.20 %\n",
      "[epoch: 32, batch_idx: 45]: loss: 0.003 , acc: 90.10 %\n",
      "[epoch: 32, batch_idx: 50]: loss: 0.004 , acc: 90.20 %\n",
      "[epoch: 32, batch_idx: 55]: loss: 0.004 , acc: 90.10 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 33, batch_idx: 5]: loss: 0.004 , acc: 88.56 %\n",
      "[epoch: 33, batch_idx: 10]: loss: 0.004 , acc: 89.12 %\n",
      "[epoch: 33, batch_idx: 15]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 33, batch_idx: 20]: loss: 0.003 , acc: 89.94 %\n",
      "[epoch: 33, batch_idx: 25]: loss: 0.004 , acc: 90.31 %\n",
      "[epoch: 33, batch_idx: 30]: loss: 0.003 , acc: 89.84 %\n",
      "[epoch: 33, batch_idx: 35]: loss: 0.004 , acc: 89.61 %\n",
      "[epoch: 33, batch_idx: 40]: loss: 0.003 , acc: 89.51 %\n",
      "[epoch: 33, batch_idx: 45]: loss: 0.003 , acc: 89.65 %\n",
      "[epoch: 33, batch_idx: 50]: loss: 0.003 , acc: 89.98 %\n",
      "[epoch: 33, batch_idx: 55]: loss: 0.004 , acc: 89.69 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 34, batch_idx: 5]: loss: 0.004 , acc: 88.01 %\n",
      "[epoch: 34, batch_idx: 10]: loss: 0.003 , acc: 89.55 %\n",
      "[epoch: 34, batch_idx: 15]: loss: 0.004 , acc: 89.80 %\n",
      "[epoch: 34, batch_idx: 20]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 34, batch_idx: 25]: loss: 0.004 , acc: 89.75 %\n",
      "[epoch: 34, batch_idx: 30]: loss: 0.004 , acc: 89.59 %\n",
      "[epoch: 34, batch_idx: 35]: loss: 0.004 , acc: 89.12 %\n",
      "[epoch: 34, batch_idx: 40]: loss: 0.003 , acc: 89.82 %\n",
      "[epoch: 34, batch_idx: 45]: loss: 0.003 , acc: 90.18 %\n",
      "[epoch: 34, batch_idx: 50]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 34, batch_idx: 55]: loss: 0.003 , acc: 90.57 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 35, batch_idx: 5]: loss: 0.004 , acc: 87.76 %\n",
      "[epoch: 35, batch_idx: 10]: loss: 0.004 , acc: 89.51 %\n",
      "[epoch: 35, batch_idx: 15]: loss: 0.003 , acc: 90.37 %\n",
      "[epoch: 35, batch_idx: 20]: loss: 0.003 , acc: 90.20 %\n",
      "[epoch: 35, batch_idx: 25]: loss: 0.004 , acc: 90.06 %\n",
      "[epoch: 35, batch_idx: 30]: loss: 0.004 , acc: 89.88 %\n",
      "[epoch: 35, batch_idx: 35]: loss: 0.004 , acc: 89.39 %\n",
      "[epoch: 35, batch_idx: 40]: loss: 0.003 , acc: 89.82 %\n",
      "[epoch: 35, batch_idx: 45]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 35, batch_idx: 50]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 35, batch_idx: 55]: loss: 0.003 , acc: 90.21 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 36, batch_idx: 5]: loss: 0.004 , acc: 87.68 %\n",
      "[epoch: 36, batch_idx: 10]: loss: 0.003 , acc: 89.80 %\n",
      "[epoch: 36, batch_idx: 15]: loss: 0.004 , acc: 89.63 %\n",
      "[epoch: 36, batch_idx: 20]: loss: 0.003 , acc: 90.72 %\n",
      "[epoch: 36, batch_idx: 25]: loss: 0.003 , acc: 90.25 %\n",
      "[epoch: 36, batch_idx: 30]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 36, batch_idx: 35]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 36, batch_idx: 40]: loss: 0.004 , acc: 89.80 %\n",
      "[epoch: 36, batch_idx: 45]: loss: 0.003 , acc: 89.65 %\n",
      "[epoch: 36, batch_idx: 50]: loss: 0.004 , acc: 90.08 %\n",
      "[epoch: 36, batch_idx: 55]: loss: 0.004 , acc: 89.34 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 37, batch_idx: 5]: loss: 0.004 , acc: 88.54 %\n",
      "[epoch: 37, batch_idx: 10]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 37, batch_idx: 15]: loss: 0.003 , acc: 89.24 %\n",
      "[epoch: 37, batch_idx: 20]: loss: 0.003 , acc: 90.31 %\n",
      "[epoch: 37, batch_idx: 25]: loss: 0.003 , acc: 90.00 %\n",
      "[epoch: 37, batch_idx: 30]: loss: 0.004 , acc: 89.96 %\n",
      "[epoch: 37, batch_idx: 35]: loss: 0.003 , acc: 89.24 %\n",
      "[epoch: 37, batch_idx: 40]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 37, batch_idx: 45]: loss: 0.003 , acc: 90.21 %\n",
      "[epoch: 37, batch_idx: 50]: loss: 0.003 , acc: 90.33 %\n",
      "[epoch: 37, batch_idx: 55]: loss: 0.003 , acc: 89.53 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 40.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 17.0 % \n",
      "[epoch: 38, batch_idx: 5]: loss: 0.003 , acc: 88.45 %\n",
      "[epoch: 38, batch_idx: 10]: loss: 0.003 , acc: 89.82 %\n",
      "[epoch: 38, batch_idx: 15]: loss: 0.003 , acc: 89.84 %\n",
      "[epoch: 38, batch_idx: 20]: loss: 0.003 , acc: 90.39 %\n",
      "[epoch: 38, batch_idx: 25]: loss: 0.004 , acc: 90.53 %\n",
      "[epoch: 38, batch_idx: 30]: loss: 0.003 , acc: 89.71 %\n",
      "[epoch: 38, batch_idx: 35]: loss: 0.004 , acc: 89.39 %\n",
      "[epoch: 38, batch_idx: 40]: loss: 0.004 , acc: 89.53 %\n",
      "[epoch: 38, batch_idx: 45]: loss: 0.004 , acc: 89.38 %\n",
      "[epoch: 38, batch_idx: 50]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 38, batch_idx: 55]: loss: 0.003 , acc: 89.79 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 39, batch_idx: 5]: loss: 0.004 , acc: 88.18 %\n",
      "[epoch: 39, batch_idx: 10]: loss: 0.003 , acc: 89.36 %\n",
      "[epoch: 39, batch_idx: 15]: loss: 0.004 , acc: 89.86 %\n",
      "[epoch: 39, batch_idx: 20]: loss: 0.003 , acc: 90.35 %\n",
      "[epoch: 39, batch_idx: 25]: loss: 0.003 , acc: 90.35 %\n",
      "[epoch: 39, batch_idx: 30]: loss: 0.003 , acc: 90.00 %\n",
      "[epoch: 39, batch_idx: 35]: loss: 0.004 , acc: 89.82 %\n",
      "[epoch: 39, batch_idx: 40]: loss: 0.004 , acc: 89.57 %\n",
      "[epoch: 39, batch_idx: 45]: loss: 0.003 , acc: 89.59 %\n",
      "[epoch: 39, batch_idx: 50]: loss: 0.003 , acc: 88.93 %\n",
      "[epoch: 39, batch_idx: 55]: loss: 0.003 , acc: 89.80 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 40, batch_idx: 5]: loss: 0.004 , acc: 88.12 %\n",
      "[epoch: 40, batch_idx: 10]: loss: 0.003 , acc: 90.59 %\n",
      "[epoch: 40, batch_idx: 15]: loss: 0.003 , acc: 89.57 %\n",
      "[epoch: 40, batch_idx: 20]: loss: 0.004 , acc: 90.14 %\n",
      "[epoch: 40, batch_idx: 25]: loss: 0.003 , acc: 89.61 %\n",
      "[epoch: 40, batch_idx: 30]: loss: 0.004 , acc: 89.38 %\n",
      "[epoch: 40, batch_idx: 35]: loss: 0.003 , acc: 90.08 %\n",
      "[epoch: 40, batch_idx: 40]: loss: 0.003 , acc: 89.51 %\n",
      "[epoch: 40, batch_idx: 45]: loss: 0.003 , acc: 89.63 %\n",
      "[epoch: 40, batch_idx: 50]: loss: 0.003 , acc: 88.81 %\n",
      "[epoch: 40, batch_idx: 55]: loss: 0.004 , acc: 89.32 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 41, batch_idx: 5]: loss: 0.003 , acc: 88.45 %\n",
      "[epoch: 41, batch_idx: 10]: loss: 0.003 , acc: 90.45 %\n",
      "[epoch: 41, batch_idx: 15]: loss: 0.003 , acc: 89.65 %\n",
      "[epoch: 41, batch_idx: 20]: loss: 0.003 , acc: 89.30 %\n",
      "[epoch: 41, batch_idx: 25]: loss: 0.003 , acc: 90.18 %\n",
      "[epoch: 41, batch_idx: 30]: loss: 0.003 , acc: 89.53 %\n",
      "[epoch: 41, batch_idx: 35]: loss: 0.004 , acc: 89.77 %\n",
      "[epoch: 41, batch_idx: 40]: loss: 0.003 , acc: 89.63 %\n",
      "[epoch: 41, batch_idx: 45]: loss: 0.003 , acc: 89.96 %\n",
      "[epoch: 41, batch_idx: 50]: loss: 0.004 , acc: 90.21 %\n",
      "[epoch: 41, batch_idx: 55]: loss: 0.004 , acc: 89.51 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 16.0 % \n",
      "[epoch: 42, batch_idx: 5]: loss: 0.004 , acc: 87.62 %\n",
      "[epoch: 42, batch_idx: 10]: loss: 0.004 , acc: 88.85 %\n",
      "[epoch: 42, batch_idx: 15]: loss: 0.003 , acc: 90.27 %\n",
      "[epoch: 42, batch_idx: 20]: loss: 0.003 , acc: 90.23 %\n",
      "[epoch: 42, batch_idx: 25]: loss: 0.004 , acc: 90.49 %\n",
      "[epoch: 42, batch_idx: 30]: loss: 0.003 , acc: 90.12 %\n",
      "[epoch: 42, batch_idx: 35]: loss: 0.003 , acc: 89.63 %\n",
      "[epoch: 42, batch_idx: 40]: loss: 0.004 , acc: 89.59 %\n",
      "[epoch: 42, batch_idx: 45]: loss: 0.004 , acc: 89.63 %\n",
      "[epoch: 42, batch_idx: 50]: loss: 0.003 , acc: 90.02 %\n",
      "[epoch: 42, batch_idx: 55]: loss: 0.003 , acc: 89.98 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 17.0 % \n",
      "[epoch: 43, batch_idx: 5]: loss: 0.003 , acc: 88.22 %\n",
      "[epoch: 43, batch_idx: 10]: loss: 0.003 , acc: 90.06 %\n",
      "[epoch: 43, batch_idx: 15]: loss: 0.004 , acc: 88.65 %\n",
      "[epoch: 43, batch_idx: 20]: loss: 0.003 , acc: 89.84 %\n",
      "[epoch: 43, batch_idx: 25]: loss: 0.004 , acc: 89.65 %\n",
      "[epoch: 43, batch_idx: 30]: loss: 0.003 , acc: 89.98 %\n",
      "[epoch: 43, batch_idx: 35]: loss: 0.003 , acc: 89.80 %\n",
      "[epoch: 43, batch_idx: 40]: loss: 0.004 , acc: 90.62 %\n",
      "[epoch: 43, batch_idx: 45]: loss: 0.004 , acc: 90.00 %\n",
      "[epoch: 43, batch_idx: 50]: loss: 0.003 , acc: 89.84 %\n",
      "[epoch: 43, batch_idx: 55]: loss: 0.003 , acc: 89.96 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 13.0 % \n",
      "[epoch: 44, batch_idx: 5]: loss: 0.003 , acc: 87.87 %\n",
      "[epoch: 44, batch_idx: 10]: loss: 0.004 , acc: 89.36 %\n",
      "[epoch: 44, batch_idx: 15]: loss: 0.003 , acc: 89.14 %\n",
      "[epoch: 44, batch_idx: 20]: loss: 0.003 , acc: 90.35 %\n",
      "[epoch: 44, batch_idx: 25]: loss: 0.003 , acc: 89.77 %\n",
      "[epoch: 44, batch_idx: 30]: loss: 0.003 , acc: 90.08 %\n",
      "[epoch: 44, batch_idx: 35]: loss: 0.004 , acc: 89.90 %\n",
      "[epoch: 44, batch_idx: 40]: loss: 0.003 , acc: 90.43 %\n",
      "[epoch: 44, batch_idx: 45]: loss: 0.003 , acc: 89.92 %\n",
      "[epoch: 44, batch_idx: 50]: loss: 0.003 , acc: 89.51 %\n",
      "[epoch: 44, batch_idx: 55]: loss: 0.003 , acc: 89.20 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 45, batch_idx: 5]: loss: 0.003 , acc: 88.74 %\n",
      "[epoch: 45, batch_idx: 10]: loss: 0.003 , acc: 90.59 %\n",
      "[epoch: 45, batch_idx: 15]: loss: 0.003 , acc: 90.16 %\n",
      "[epoch: 45, batch_idx: 20]: loss: 0.003 , acc: 89.47 %\n",
      "[epoch: 45, batch_idx: 25]: loss: 0.003 , acc: 89.96 %\n",
      "[epoch: 45, batch_idx: 30]: loss: 0.003 , acc: 89.94 %\n",
      "[epoch: 45, batch_idx: 35]: loss: 0.003 , acc: 90.31 %\n",
      "[epoch: 45, batch_idx: 40]: loss: 0.003 , acc: 89.22 %\n",
      "[epoch: 45, batch_idx: 45]: loss: 0.003 , acc: 89.67 %\n",
      "[epoch: 45, batch_idx: 50]: loss: 0.003 , acc: 89.96 %\n",
      "[epoch: 45, batch_idx: 55]: loss: 0.004 , acc: 89.22 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 17.0 % \n",
      "[epoch: 46, batch_idx: 5]: loss: 0.004 , acc: 87.55 %\n",
      "[epoch: 46, batch_idx: 10]: loss: 0.003 , acc: 90.49 %\n",
      "[epoch: 46, batch_idx: 15]: loss: 0.003 , acc: 90.31 %\n",
      "[epoch: 46, batch_idx: 20]: loss: 0.004 , acc: 89.41 %\n",
      "[epoch: 46, batch_idx: 25]: loss: 0.004 , acc: 89.12 %\n",
      "[epoch: 46, batch_idx: 30]: loss: 0.003 , acc: 89.32 %\n",
      "[epoch: 46, batch_idx: 35]: loss: 0.003 , acc: 90.04 %\n",
      "[epoch: 46, batch_idx: 40]: loss: 0.004 , acc: 90.02 %\n",
      "[epoch: 46, batch_idx: 45]: loss: 0.003 , acc: 90.39 %\n",
      "[epoch: 46, batch_idx: 50]: loss: 0.003 , acc: 89.77 %\n",
      "[epoch: 46, batch_idx: 55]: loss: 0.004 , acc: 89.80 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 47, batch_idx: 5]: loss: 0.003 , acc: 89.04 %\n",
      "[epoch: 47, batch_idx: 10]: loss: 0.004 , acc: 89.73 %\n",
      "[epoch: 47, batch_idx: 15]: loss: 0.003 , acc: 90.00 %\n",
      "[epoch: 47, batch_idx: 20]: loss: 0.003 , acc: 89.67 %\n",
      "[epoch: 47, batch_idx: 25]: loss: 0.003 , acc: 90.41 %\n",
      "[epoch: 47, batch_idx: 30]: loss: 0.003 , acc: 89.47 %\n",
      "[epoch: 47, batch_idx: 35]: loss: 0.003 , acc: 89.63 %\n",
      "[epoch: 47, batch_idx: 40]: loss: 0.004 , acc: 89.49 %\n",
      "[epoch: 47, batch_idx: 45]: loss: 0.004 , acc: 89.86 %\n",
      "[epoch: 47, batch_idx: 50]: loss: 0.003 , acc: 90.12 %\n",
      "[epoch: 47, batch_idx: 55]: loss: 0.003 , acc: 90.27 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 15.0 % \n",
      "[epoch: 48, batch_idx: 5]: loss: 0.003 , acc: 88.68 %\n",
      "[epoch: 48, batch_idx: 10]: loss: 0.003 , acc: 89.59 %\n",
      "[epoch: 48, batch_idx: 15]: loss: 0.003 , acc: 90.31 %\n",
      "[epoch: 48, batch_idx: 20]: loss: 0.003 , acc: 89.36 %\n",
      "[epoch: 48, batch_idx: 25]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 48, batch_idx: 30]: loss: 0.003 , acc: 89.80 %\n",
      "[epoch: 48, batch_idx: 35]: loss: 0.004 , acc: 89.79 %\n",
      "[epoch: 48, batch_idx: 40]: loss: 0.003 , acc: 90.66 %\n",
      "[epoch: 48, batch_idx: 45]: loss: 0.004 , acc: 89.92 %\n",
      "[epoch: 48, batch_idx: 50]: loss: 0.003 , acc: 89.51 %\n",
      "[epoch: 48, batch_idx: 55]: loss: 0.003 , acc: 89.88 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 49, batch_idx: 5]: loss: 0.003 , acc: 88.22 %\n",
      "[epoch: 49, batch_idx: 10]: loss: 0.003 , acc: 90.53 %\n",
      "[epoch: 49, batch_idx: 15]: loss: 0.003 , acc: 89.34 %\n",
      "[epoch: 49, batch_idx: 20]: loss: 0.003 , acc: 89.55 %\n",
      "[epoch: 49, batch_idx: 25]: loss: 0.003 , acc: 89.59 %\n",
      "[epoch: 49, batch_idx: 30]: loss: 0.003 , acc: 89.34 %\n",
      "[epoch: 49, batch_idx: 35]: loss: 0.003 , acc: 90.08 %\n",
      "[epoch: 49, batch_idx: 40]: loss: 0.004 , acc: 89.86 %\n",
      "[epoch: 49, batch_idx: 45]: loss: 0.003 , acc: 90.12 %\n",
      "[epoch: 49, batch_idx: 50]: loss: 0.004 , acc: 90.18 %\n",
      "[epoch: 49, batch_idx: 55]: loss: 0.003 , acc: 90.64 %\n",
      "[batch_index: 0]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 20.0 % \n",
      "Average accuracy on val set: 14.0 % \n",
      "[epoch: 50, batch_idx: 5]: loss: 0.003 , acc: 88.41 %\n",
      "[epoch: 50, batch_idx: 10]: loss: 0.003 , acc: 89.88 %\n",
      "[epoch: 50, batch_idx: 15]: loss: 0.003 , acc: 90.04 %\n",
      "[epoch: 50, batch_idx: 20]: loss: 0.003 , acc: 89.82 %\n",
      "[epoch: 50, batch_idx: 25]: loss: 0.004 , acc: 89.16 %\n",
      "[epoch: 50, batch_idx: 30]: loss: 0.003 , acc: 90.02 %\n",
      "[epoch: 50, batch_idx: 35]: loss: 0.003 , acc: 89.94 %\n",
      "[epoch: 50, batch_idx: 40]: loss: 0.004 , acc: 89.38 %\n",
      "[epoch: 50, batch_idx: 45]: loss: 0.004 , acc: 89.80 %\n",
      "[epoch: 50, batch_idx: 50]: loss: 0.003 , acc: 90.16 %\n",
      "[epoch: 50, batch_idx: 55]: loss: 0.003 , acc: 90.51 %\n",
      "[batch_index: 0]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 1]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 2]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 3]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 4]: Accuracy on val set: 20.0 % \n",
      "[batch_index: 5]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 6]: Accuracy on val set: 0.0 % \n",
      "[batch_index: 7]: Accuracy on val set: 10.0 % \n",
      "[batch_index: 8]: Accuracy on val set: 30.0 % \n",
      "[batch_index: 9]: Accuracy on val set: 10.0 % \n",
      "Average accuracy on val set: 16.0 % \n"
     ]
    }
   ],
   "source": [
    "train_loss = 0.0  # 这整个epoch的loss清零\n",
    "total = 0\n",
    "correct = 0\n",
    "epoch = 50\n",
    "#log to record loss and acc\n",
    "log=np.zeros([epoch,3])#train_loss,val_loss,val_accuracy\n",
    "iter_num = 0\n",
    "for i in range(epoch):\n",
    "    train_loss_list = []\n",
    "    for batch_idx, traindata in enumerate(data_train_loader):\n",
    "        iter_num += 1\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        data, labels = traindata['data'].to(device), traindata['label'].to(device)\n",
    "        outputs = model.forward(data)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = nf.cross_entropy(outputs, labels)\n",
    "        writer.add_scalar(\"Loss/train\", loss, iter_num)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 把运行中的loss累加起来\n",
    "        train_loss_list += [loss.item()]\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += data.shape[0]\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if batch_idx % 5 == 4:  # 不想要每一次都出loss，浪费时间，选择每5次出一个平均损失,和准确率\n",
    "            print('[epoch: %d, batch_idx: %d]: loss: %.3f , acc: %.2f %%'\n",
    "                    % (i + 1, batch_idx + 1, loss / 100, 100. * correct / total))\n",
    "            writer.add_scalar('train accuracy per 10 batches', 100. * correct / total, iter_num)\n",
    "            loss = 0.0  \n",
    "            correct = 0  \n",
    "            total = 0\n",
    "    scheduler.step()  # 优化并更新学习率\n",
    "    log[epoch-1,0]=np.mean(train_loss_list)\n",
    "    ## 模型验证\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() # 切换模型为测试状态(没加drop_out层，因此这句话可以随便注释掉)\n",
    "    val_loss = []\n",
    "    with torch.no_grad():  # 测试集不用算梯度\n",
    "        for batch_idx, valdata in enumerate(data_val_loader):\n",
    "            data, labels = valdata['data'].to(device), valdata['label'].to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)  # dim = 1 列是第0个维度，行是第1个维度，沿着行(第1个维度)去找1.最大值和2.最大值的下标\n",
    "            loss = nf.cross_entropy(outputs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            total += labels.size(0)  # 张量之间的比较运算\n",
    "            correct_batch = predicted.eq(labels).sum().item()\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            acc_batch = correct_batch / labels.size(0)\n",
    "            # print(labels.size(0))\n",
    "            print('[batch_index: %d]: Accuracy on val set: %.1f %% ' % (batch_idx, 100 * acc_batch))  # 求测试的准确率，正确数/总数\n",
    "            predicted_list = predicted.tolist()\n",
    "            targets_list = labels.tolist()\n",
    "            writer.add_scalar('val accuracy per batch', 100 * acc_batch, batch_idx)\n",
    "    acc = correct / total\n",
    "    print('Average accuracy on val set: %.1f %% ' % (100. * acc))  # 求测试的准确率，正确数/总数\n",
    "    log[epoch-1,1]= np.mean(val_loss)\n",
    "    log[epoch-1,2]= acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part6.绘制训练与验证时的准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.33315262 2.45718439 0.16      ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the curve of loss and acc\n",
    "print(log)\n",
    "x=np.arange(epoch)\n",
    "x=x+1\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(x,log[:,0],linestyle='-',color='r',label='train loss',linewidth=2)\n",
    "plt.plot(x,log[:,1],linestyle='-',color='b',label='val loss',linewidth=2)\n",
    "plt.plot(x,log[:,2],linestyle='--',color='g',label='val acc',linewidth=2)\n",
    "plt.title('Training loss and accuracy',fontsize=10)\n",
    "plt.xlabel('epoch',fontsize=10)\n",
    "plt.ylabel('value',fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "plt.ylim(0,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part7.保存模型的状态字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等两次完整的迭代进行完毕后，保存训练好的模型及其参数\n",
    "save_info = {  # 保存的信息: 1.迭代步数 2.优化器的状态字典 3.模型的状态字典\n",
    "    \"iter_num\": iter_num, \"optimizer\": optimizer.state_dict(), \"model\": model.state_dict()\n",
    "}\n",
    "save_path = \"../Results/model.pth\"  # 将模型存储的位置在当前根目录的文件夹中\n",
    "torch.save(save_info, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part8.模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# print(data_test_loader.batch_size)\n",
    "predicted_list = []\n",
    "model.eval() # 切换模型为测试状态(没加drop_out层，因此这句话可以随便注释掉)\n",
    "with torch.no_grad():  # 测试集不用算梯度\n",
    "    for batch_idx, testdata in enumerate(data_test_loader):\n",
    "        data = testdata['data'].to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.to('cpu').data, dim=1)  # dim = 1 列是第0个维度，行是第1个维度，沿着行(第1个维度)去找1.最大值和2.最大值的下标\n",
    "        # print(predicted.shape)\n",
    "        predicted = predicted.tolist()\n",
    "        if batch_idx <= math.floor(len(test_dataset)/data_test_loader.batch_size) -1:\n",
    "            for i in range(data.size(0)):\n",
    "                predicted_list.append(predicted[i])\n",
    "        else:\n",
    "            for i in range(len(test_dataset) - batch_idx * data_test_loader.batch_size):\n",
    "                predicted_list.append(predicted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part9.将模型测试结果存入.txt和.csv中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果写入Predict.txt文件中\n",
    "count = 0\n",
    "with open('../Results/Predict.txt', 'w') as file:\n",
    "    # 遍历列表中的元素并将其写入文件\n",
    "    for item in predicted_list:\n",
    "        file.write(str(count) + '.npy'+ ' ')\n",
    "        file.write(str(item) + '\\n')\n",
    "        count = count + 1\n",
    "# 将预测结果写入Predict.csv文件中\n",
    "with open('../Results/Predict.csv', 'w') as file:\n",
    "    file.write(\"predicted class label\" + '\\n')\n",
    "    # 遍历列表中的元素并将其写入文件\n",
    "    for item in predicted_list:\n",
    "        file.write(str(item) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('AAI_Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb629c1a6c6048ec23970cc4b70d31a5f99af71a13cd362ad1e3e50eaecb040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
